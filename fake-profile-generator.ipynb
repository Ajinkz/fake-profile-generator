{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import _pickle as pickle\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "biolist = []\n",
    "name_list = []\n",
    "age_list = []\n",
    "# occupation_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of website are providing fake data geneartion tools, here are the list of a few website.\n",
    "1. https://www.fakepersongenerator.com/Index/generate \n",
    "2. https://randomuser.me/documentation#format \n",
    "3. https://www.character-generator.org.uk/bio/ \n",
    "4. https://www.dating-profile-generator.org.uk/create.php?type=1 \n",
    "Webscraping code depends upon website. I will be using https://www.character-generator.org.uk/bio/ in my code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.character-generator.org.uk/bio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launch WebDriver instance\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# launch website\n",
    "driver.get(URL)\n",
    "\n",
    "# find required element and perform action \n",
    "driver.find_element_by_id('fill_all').click()\n",
    "driver.find_element_by_id('quick_submit').click()\n",
    "\n",
    "#wait for reponse\n",
    "time.sleep(2)\n",
    "\n",
    "# get new url\n",
    "url = driver.current_url\n",
    "\n",
    "#get conents from url\n",
    "page = requests.get(url)\n",
    "soup = bs(page.content)\n",
    "biostr=''\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    # Getting the bios\n",
    "    bios = soup.find('div', class_='bio').find_all('p')\n",
    "\n",
    "    # Adding to a list of the bios\n",
    "    for i in bios:\n",
    "        biostr += re.sub('<p>|</p>','',str(i))\n",
    "        \n",
    "        # To collect name, age from first string\n",
    "        name, age = ' '.join(biostr.split('.')[0].split(' ')[0:3]),int(re.findall(\"\\d+\", biostr.split('.')[0])[0])\n",
    "        \n",
    "        # s = biostr.split('.')[0]\n",
    "        # occupation = s[s.find(\"-old \")+ len(\"-old \"):s.find(\" who\")]\n",
    "\n",
    "    biolist.append(biostr)\n",
    "    name_list.append(name)\n",
    "    age_list.append(age)\n",
    "    # occupation_list.append(occupation)\n",
    "    \n",
    "    # close the instance\n",
    "    driver.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "len(biolist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip all three list and create a dataframe\n",
    "profile = pd.DataFrame(zip(name_list, age_list,biolist), columns=['name','age','bios'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>bios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Richard Luke Trescothik</td>\n",
       "      <td>21</td>\n",
       "      <td>Richard Luke Trescothik is a 21-year-old trade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mark Rick Sweet</td>\n",
       "      <td>29</td>\n",
       "      <td>Mark Rick Sweet is a 29-year-old theatre actor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name  age  \\\n",
       "0  Richard Luke Trescothik   21   \n",
       "1          Mark Rick Sweet   29   \n",
       "\n",
       "                                                bios  \n",
       "0  Richard Luke Trescothik is a 21-year-old trade...  \n",
       "1  Mark Rick Sweet is a 29-year-old theatre actor...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can automate this process for gathering large number of fake profiles data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomizing the refresh rate\n",
    "seq = [i/10 for i in range(8,18)]\n",
    "\n",
    "\n",
    "# Gathering bios by looping and refreshing the web page\n",
    "for _ in tqdm(range(1000)):\n",
    "    \n",
    "    # launch WebDriver instance\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    # launch website\n",
    "    driver.get(URL)\n",
    "    # find required element and perform action \n",
    "    driver.find_element_by_id('fill_all').click()\n",
    "    driver.find_element_by_id('quick_submit').click()\n",
    "    #wait for reponse\n",
    "    time.sleep(2)\n",
    "    # get new url\n",
    "    url = driver.current_url\n",
    "    #get conents from url\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content)\n",
    "    biostr=''\n",
    "\n",
    "    try:\n",
    "        # Getting the bios\n",
    "        bios = soup.find('div', class_='bio').find_all('p')\n",
    "\n",
    "        # Adding to a list of the bios\n",
    "        for i in bios:\n",
    "            biostr += re.sub('<p>|</p>','',str(i)) \n",
    "            \n",
    "            name, age = ' '.join(biostr.split('.')[0].split(' ')[0:3]),int(re.findall(\"\\d+\", biostr.split('.')[0])[0])\n",
    "        \n",
    "            # s = biostr.split('.')[0]\n",
    "            # occupation = s[s.find(\"-old \")+ len(\"-old \"):s.find(\" who\")]\n",
    "\n",
    "        biolist.append(biostr)\n",
    "        name_list.append(name)\n",
    "        age_list.append(age)\n",
    "\n",
    "        # close the instance\n",
    "        driver.close()\n",
    "        print(len(biolist))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    # Sleeping \n",
    "    time.sleep(random.choice(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(biolist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pd.DataFrame(zip(name_list, age_list,biolist), columns=['name','age','bios'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can serialise created datframe object for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"bios_data0.pkl\", \"wb\") as fp:\n",
    "    pickle.dump(profile, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
